# This config is equivalent to both the '.circleci/extended/orb-free.yml' and the base '.circleci/config.yml'
version: 2.1

# Orbs are reusable packages of CircleCI configuration that you may share across projects, enabling you to create encapsulated, parameterized commands, jobs, and executors that can be used across multiple projects.
# See: https://circleci.com/docs/orb-intro/
orbs:
  node: circleci/node@4.7

# Invoke jobs via workflows
# See: https://circleci.com/docs/configuration-reference/#workflows
workflows:
  sample: # This is the name of the workflow, feel free to change it to better match your workflow.
    # Inside the workflow, you define the jobs you want to run.
    jobs:
      - node/test:
          # This is the node version to use for the `cimg/node` tag
          # Relevant tags can be found on the CircleCI Developer Hub
          # https://circleci.com/developer/images/image/cimg/node
          version: '16.10'
          # If you are using yarn, change the line below from "npm" to "yarn"
          pkg-manager: npm

import telebot
import requests
import json

# GPT-3 API key
API_KEY = "<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>"

# BotFather token
BOT_TOKEN = "<@Oday199_bot>"

# Create a new Telegram bot
bot = telebot.TeleBot(BOT_TOKEN)

# Handle the /start command
@bot.message_handler(commands=['start'])
def start(message):
    bot.reply_to(message, 'Hello! I am your GPT-3 bot. I can answer your questions using OpenAI GPT-3. Type /help to get started.')

    # Handle the /help command
    @bot.message_handler(commands=['help'])
    def help(message):
        bot.reply_to(message, 'To use me, just type your question and I will try to answer it using OpenAI GPT-3. Have fun!')

        # Handle all other messages
        @bot.message_handler(func=lambda message: True)
        def answer_question(message):
            # Get the question from the user
                question = message.text

                    # Make a request to the GPT-3 API
                        url = 'https://api.openai.com/v1/engines/davinci/completions'
                            headers = {
                                    'Content-Type': 'application/json',
                                            'Authorization': 'Bearer ' + API_KEY
                                                }
                                                    data = {
                                                            'prompt': question,
                                                                    'max_tokens': 100
                                                                        }
                                                                            response = requests.post(url, headers=headers, data=json.dumps(data))
                                                                                response_json = response.json()

                                                                                    # Get the answer from the response
                                                                                        answer = response_json['choices'][0]['text']

                                                                                            # Send the answer to the user
                                                                                                bot.reply_to(message, answer)

                                                                                                # Run the bot
                                                                                                bot.polling()